{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# PyTorch Fundamentals\n",
        "\n",
        "This notebook deals with the basic building block of machine learning and deep learning, the tensor.\n",
        "\n",
        "| **Topic** | **Contents** |\n",
        "| ----- | ----- |\n",
        "| **Introduction to tensors** | Tensors are the basic building block of all of machine learning and deep learning. |\n",
        "| **Creating tensors** | Tensors can represent almost any kind of data (images, words, tables of numbers). |\n",
        "| **Getting information from tensors** | If you can put information into a tensor, you'll want to get it out too. |\n",
        "| **Manipulating tensors** | Machine learning algorithms (like neural networks) involve manipulating tensors in many different ways such as adding, multiplying, combining. |\n",
        "| **Dealing with tensor shapes** | One of the most common issues in machine learning is dealing with shape mismatches (trying to mix wrong shaped tensors with other tensors). |\n",
        "| **Indexing on tensors** | If you've indexed on a Python list or NumPy array, it's very similar with tensors, except they can have far more dimensions. |\n",
        "| **Mixing PyTorch tensors and NumPy** | PyTorch plays with tensors ([`torch.Tensor`](https://pytorch.org/docs/stable/tensors.html)), NumPy likes arrays ([`np.ndarray`](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html)) sometimes you'll want to mix and match these. |\n",
        "| **Reproducibility** | Machine learning is very experimental and since it uses a lot of *randomness* to work, sometimes you'll want that *randomness* to not be so random. |\n",
        "| **Running tensors on GPU** | GPUs (Graphics Processing Units) make your code faster, PyTorch makes it easy to run your code on GPUs. |"
      ],
      "metadata": {
        "id": "v2L_sXkfPd3a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "print(torch.__version__)"
      ],
      "metadata": {
        "id": "mWTyJi_KB_bA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0795ed0-a81d-45cb-e227-8453861663e3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.0+cu126\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction to Tensors"
      ],
      "metadata": {
        "id": "cuvPfASoJ5Ac"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tensors are the fundamental building block of machine learning.\n",
        "**They are numerical representations (encodings) of data.**\n",
        "\n",
        "\n",
        "For example, you could represent an image as a tensor with shape `[3, 224, 224]` which would mean `[colour_channels, height, width]`, as in the image has `3` colour channels (red, green, blue), a height of `224` pixels and a width of `224` pixels.\n",
        "\n",
        "![example of going from an input image to a tensor representation of the image, image gets broken down into 3 colour channels as well as numbers to represent the height and width](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/00-tensor-shape-example-of-image.png)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3YqXRxY-QHIY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating Tensors\n",
        "PyTorch tensors are created using `torch.Tensor()`\n",
        "\n",
        "\n",
        "[read through the documentation on `torch.Tensor`](https://pytorch.org/docs/stable/tensors.html)"
      ],
      "metadata": {
        "id": "TIWNtIvRJ5EO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# scalar - a single number and in tensor-speak it's a zero dimension tensor\n",
        "# torch.tensor is a pytorch tensor datatype\n",
        "\n",
        "scalar = torch.tensor(7)\n",
        "print(scalar)"
      ],
      "metadata": {
        "id": "bIWe1_1xJ5Hd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e1c3ab8-2e5a-4c32-9e70-7d55f0fb5882"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check the dimensions of a tensor - ndim\n",
        "scalar.ndim\n",
        "\n",
        "# a scalar has no dimensions (single number)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fwy3zaRZYWmL",
        "outputId": "1b60d0fe-2324-4a3e-c509-3816f069b2bf"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A vector is a single dimension tensor (1D)\n",
        "\n",
        "As in, you could have a vector `[3, 2]` to describe `[bedrooms, bathrooms]` in your house. Or you could have `[3, 2, 2]` to describe `[bedrooms, bathrooms, car_parks]` in your house."
      ],
      "metadata": {
        "id": "lXhoynu4VvmL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vector - 1D tensor\n",
        "vector = torch.tensor([7, 7])\n",
        "vector"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJJu3mQKYYi1",
        "outputId": "18c06e6e-e0cc-43d1-88b3-7a44a95e94b7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([7, 7])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vector.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QG98uPgwZIJt",
        "outputId": "4781d4b3-5598-430c-e410-48d3524695a8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can tell the number of dimensions a tensor in PyTorch has by the number of square brackets on the outside (`[`) and you only need to count one side.\n",
        "\n",
        "Another important concept for tensors is their `shape` attribute. The shape tells you how the elements inside them are arranged."
      ],
      "metadata": {
        "id": "ww854emBWRrM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vector.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oaYVzXnRZIL2",
        "outputId": "ebf768e9-6288-416c-b8df-23a49486e0a2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above returns `torch.Size([2])` which means our vector has a shape of `[2]`. This is because of the two elements we placed inside the square brackets (`[7, 7]`)."
      ],
      "metadata": {
        "id": "DYRUHke6WX4R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Matrix - 2D tensor\n",
        "MATRIX = torch.tensor([\n",
        "    [7,8],\n",
        "     [9,10]\n",
        "    ])\n",
        "MATRIX"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3KNg04KZIOU",
        "outputId": "46fdb7db-4b18-4be9-82ca-57af8fcb3873"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 7,  8],\n",
              "        [ 9, 10]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MATRIX.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gppBvwQcZIgJ",
        "outputId": "6c3a680f-efb9-43dc-b5c3-cb0b16ea9866"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MATRIX.shape\n",
        "# 2 elements each in each dimension"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1O4dExU8aN-V",
        "outputId": "7ca6e673-013b-40b3-e152-949db595765e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MATRIX[0] # access elements in 1st dimension"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0HO85_7gaHjo",
        "outputId": "ad48c580-8da8-4c49-9bbc-42ef6e8f2bd1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([7, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tensor\n",
        "TENSOR = torch.tensor([[[1, 2, 3],\n",
        "                        [3, 6, 9],\n",
        "                        [2, 4, 5]]])\n",
        "TENSOR"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uV16sve_aYE0",
        "outputId": "431a78d7-101c-4166-fd5b-2f943bbdf035"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[1, 2, 3],\n",
              "         [3, 6, 9],\n",
              "         [2, 4, 5]]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TENSOR.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MHv5KYznaYHD",
        "outputId": "5f13e519-11e9-487b-a4df-ac82b2e8ee71"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TENSOR.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qo67_jgzaYJo",
        "outputId": "627a6307-d0d8-48ea-95c5-8614555e5a86"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 3, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "it outputs `torch.Size([1, 3, 3])`.\n",
        "\n",
        "The dimensions go outer to inner.\n",
        "\n",
        "That means there's 1 dimension of 3 by 3.\n",
        "\n",
        "![example of different tensor dimensions](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/00-pytorch-different-tensor-dimensions.png)\n",
        "\n",
        "> Note: the names martrix and tensor used interchangably. This is common. Since in PyTorch you're often dealing with `torch.Tensor`s (hence the tensor name), however, the shape and dimensions of what's inside will dictate what it actually is."
      ],
      "metadata": {
        "id": "mJqXOfF-buCZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Summary\n",
        "\n",
        "| Name | What is it? | Number of dimensions |\n",
        "| ----- | ----- | ----- |\n",
        "| **scalar** | a single number | 0 |\n",
        "| **vector** | a number with direction (e.g. wind speed with direction) but can also have many other numbers | 1 |\n",
        "| **matrix** | a 2-dimensional array of numbers | 2 |\n",
        "| **tensor** | an n-dimensional array of numbers | can be any number, a 0-dimension tensor is a scalar, a 1-dimension tensor is a vector |\n",
        "\n",
        "![scalar vector matrix tensor and what they look like](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/00-scalar-vector-matrix-tensor.png)"
      ],
      "metadata": {
        "id": "yvB9jd0IcCTc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Tensors\n",
        "\n",
        "**Why random tensors?**\n",
        "Random tensors are important because the way neural networks learn is that they start with tensors full of random numbers and then adjust those random numbers to better represent the data\n",
        "\n",
        "\n",
        "\n",
        "Machine learning models such as neural networks manipulate and seek patterns within tensors. A machine learning model often starts out with large random tensors of numbers and adjusts these random numbers as it works through data to better represent it.\n",
        "\n",
        "In essence:\n",
        "\n",
        "`Start with random numbers -> look at data -> update random numbers -> look at data -> update random numbers...`\n",
        "\n",
        "As a data scientist, you can define how the machine learning model starts (initialization), looks at data (representation) and updates (optimization) its random numbers.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "67fUzm55cO8a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a random tensor of size (3, 4) - torch.rand(size)\n",
        "\n",
        "random_tensor = torch.rand(size=(3,4))\n",
        "random_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FTbOBmVuDfqH",
        "outputId": "7d6ccf1f-0ac5-427c-b22a-162e1d1fbbc2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0282, 0.7600, 0.5963, 0.2550],\n",
              "        [0.4615, 0.3836, 0.6543, 0.4122],\n",
              "        [0.6881, 0.1613, 0.9228, 0.3272]])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random_tensor.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "id8bKk3vDfsP",
        "outputId": "38e4d08c-0753-47f9-a225-d05dac847855"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random_tensor.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rN4HOnA2Dfu3",
        "outputId": "927de35b-fe3c-470a-e9c0-ba439e236c31"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Zeroes and Ones\n",
        "\n",
        "Sometimes you'll just want to fill tensors with zeros or ones.\n",
        "\n",
        "This happens a lot with masking (like masking some of the values in one tensor with zeros to let a model know not to learn them)."
      ],
      "metadata": {
        "id": "hfdjZn0aRhsi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor of all zeros - torch.zeros(size)\n",
        "zeros = torch.zeros(size=(3 ,4))\n",
        "zeros"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p0DuVZByDf3M",
        "outputId": "a2739211-13c3-4338-c899-433c9fccdf5a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor of all ones - torch.ones()\n",
        "ones = torch.ones(size=(3 ,4))\n",
        "ones"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4m1jOLYbMrsI",
        "outputId": "601792f6-74fa-4920-b79a-78e44cb8660b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ones.dtype\n",
        "\n",
        "# dtype --> Find datatype\n",
        "# float32 is the default datatype of pytorch tensors"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nvIz2UQ4MruZ",
        "outputId": "1d817f29-769d-43a8-9135-4e47d6aff1b5"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating a range of tensors and tensors-like\n",
        "\n",
        "Sometimes you might want a range of numbers, such as 1 to 10 or 0 to 100.\n",
        "\n",
        "You can use `torch.arange(start, end, step)` to do so.\n",
        "\n",
        "Where:\n",
        "* `start` = start of range (e.g. 0)\n",
        "* `end` = end of range (e.g. 10)\n",
        "* `step` = how many steps in between each value (e.g. 1)\n",
        "\n",
        "> **Note:** In Python, you can use `range()` to create a range. However in PyTorch, `torch.range()` is deprecated and may show an error in the future.\n"
      ],
      "metadata": {
        "id": "_FMCz1oaMrwd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Create a range of tensor (random)\n",
        "tensor_random = torch.arange(start=0, end=20, step=2)\n",
        "tensor_random"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JnOrAAEzMrz_",
        "outputId": "9a442d12-4d9a-40a7-ceb6-b791dbd2d1d8"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0,  2,  4,  6,  8, 10, 12, 14, 16, 18])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sometimes you might want one tensor of a certain type with the same shape as another tensor.\n",
        "\n",
        "For example, a tensor of all zeros with the same shape as a previous tensor.\n",
        "\n",
        "To do so you can use [`torch.zeros_like(input)`](https://pytorch.org/docs/stable/generated/torch.zeros_like.html) or [`torch.ones_like(input)`](https://pytorch.org/docs/1.9.1/generated/torch.ones_like.html) which return a tensor filled with zeros or ones in the same shape as the `input` respectively."
      ],
      "metadata": {
        "id": "WSzBOxOCg9Pv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Create a tensor like (create a tensor similar in shape of another tensor)\n",
        "tensor_zeroes = torch.zeros_like(input=tensor_random)\n",
        "tensor_zeroes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMzIRzL1hNUj",
        "outputId": "a852213f-8b73-494b-d641-ef2c33dbe254"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tensor Datatypes\n",
        "\n",
        "**Note:** Tensor datatypes is one of the 3 big errors you'll run into with Pytorch and Deep Learning:\n",
        "1. Tensors not right datatype\n",
        "2. Tensors not right shape\n",
        "3. Tensors not on the right device\n",
        "\n",
        "**3 imp parameters to create tensors:**\n",
        "1) dtype\n",
        "2) device\n",
        "3) requires_grad\n"
      ],
      "metadata": {
        "id": "Oe6U1AzZhNWz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are many different [tensor datatypes available in PyTorch](https://pytorch.org/docs/stable/tensors.html#data-types).\n",
        "\n",
        "Some are specific for CPU and some are better for GPU.\n",
        "\n",
        "Generally if you see `torch.cuda` anywhere, the tensor is being used for GPU (since Nvidia GPUs use a computing toolkit called CUDA)."
      ],
      "metadata": {
        "id": "Z44ZnYj7h7uG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "float_tensor = torch.tensor([3.0, 6.0, 7.0],\n",
        "                            dtype=None, # what datatype is the tensor (e.g. float32 or float16). Default datatype in pytorch is float32\n",
        "                            device=None, # what device is your tensor on. by default, device=\"cpu\". For gpu, use device=\"cuda\"\n",
        "                            requires_grad=False # whether or not to track gradients with this tensor operations\n",
        "                            )\n",
        "print(float_tensor)\n",
        "print(float_tensor.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h08YEyFRhNZA",
        "outputId": "9a729a10-7c1c-4cf7-84f2-b855996bc774"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3., 6., 7.])\n",
            "torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aside from shape issues (tensor shapes don't match up), two of the other most common issues you'll come across in PyTorch are datatype and device issues.\n",
        "\n",
        "For example, one of tensors is `torch.float32` and the other is `torch.float16` (PyTorch often likes tensors to be the same format)."
      ],
      "metadata": {
        "id": "zaikyVRCiSPx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert/change datatype of tensor using .type()\n",
        "float_16_tensor = float_tensor.type(torch.float16) # change from 32-bit to 16-bit tensor here\n",
        "float_16_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-sz6s_WhNbS",
        "outputId": "a61bdab1-0e67-4956-b09e-d67fbf2f8754"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([3., 6., 7.], dtype=torch.float16)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Getting information from tensors (tensor attributes)\n",
        "\n",
        "Once you've created tensors, you might want to get some information from them.\n",
        "\n",
        "Three of the most common attributes you'll want to find out about tensors are:\n",
        "* `shape` - what shape is the tensor? (some operations require specific shape rules)\n",
        "* `dtype` - what datatype are the elements within the tensor stored in?\n",
        "* `device` - what device is the tensor stored on? (usually GPU or CPU)\n",
        "\n",
        "> **Note:** When you run into issues in PyTorch, it's very often one to do with one of the three attributes below."
      ],
      "metadata": {
        "id": "olq2xQTol2lU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "some_tensor = torch.rand(3,4)\n",
        "some_tensor"
      ],
      "metadata": {
        "id": "jT74IIsSl2n2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2edc0685-ecc6-432c-b925-96bcd9d9fbb2"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.4310, 0.6218, 0.6958, 0.7125],\n",
              "        [0.8786, 0.2250, 0.6819, 0.4668],\n",
              "        [0.9803, 0.5521, 0.3625, 0.1674]])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find out some details about the tensor\n",
        "print(some_tensor)\n",
        "print(f\"Datatype of tensor: {some_tensor.dtype}\")\n",
        "print(f\"Shape of tensor: {some_tensor.shape}\")\n",
        "print(f\"Device tensor is on: {some_tensor.device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GECyV0bNatA0",
        "outputId": "bbb9e25c-e2e3-4fab-f7d6-cdde173462e1"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.4310, 0.6218, 0.6958, 0.7125],\n",
            "        [0.8786, 0.2250, 0.6819, 0.4668],\n",
            "        [0.9803, 0.5521, 0.3625, 0.1674]])\n",
            "Datatype of tensor: torch.float32\n",
            "Shape of tensor: torch.Size([3, 4])\n",
            "Device tensor is on: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Manipulating Tensors (tensor operations)\n",
        "\n",
        "In deep learning, data (images, text, video, audio, protein structures, etc) gets represented as tensors.\n",
        "\n",
        "A model learns by investigating those tensors and performing a series of operations on tensors to create a representation of the patterns in the input data.\n",
        "\n",
        "Tensor operations include:\n",
        "1. Addition\n",
        "2. Subtraction\n",
        "3. Multiplication (element-wise)\n",
        "4. Division\n",
        "5. Matrix Multiplication"
      ],
      "metadata": {
        "id": "XrpSj1NkatDE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Basic Operations"
      ],
      "metadata": {
        "id": "FDbY_FWoTRuH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.tensor([1, 2, 3])\n",
        "tensor"
      ],
      "metadata": {
        "id": "bntTH-dQatFK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "852b12d1-0340-4806-d114-9a6fd4796bc0"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = tensor + 10 # add\n",
        "print(tensor)\n",
        "tensor = tensor * 2 # multiplication (element-wise)\n",
        "print(tensor)\n",
        "tensor = tensor - 5 # subtract\n",
        "print(tensor)"
      ],
      "metadata": {
        "id": "bLEQWshtl2p3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77696dc3-6b9f-40b6-be62-a494b71bbf89"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([11, 12, 13])\n",
            "tensor([22, 24, 26])\n",
            "tensor([17, 19, 21])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Matrix Multiplication\n",
        "\n",
        "Two main ways of performing multiplication in neural networks and deep learning:\n",
        "\n",
        "1. Element-wise multiplication\n",
        "2. Matrix multiplication (dot product)\n",
        "\n",
        "There are two main rules that performing matrix multiplication needs to satisfy:\n",
        "\n",
        "1. The inner dimensions must match:\n",
        "\n",
        "* `(3,2)` x `(3,2)` won't work\n",
        "* `(3, 2)` x `(2, 3)` will work\n",
        "* `(2, 3)` x `(3, 2)` will work\n",
        "\n",
        "2. The resulting matrix has the shape of the outer dimensions:\n",
        "\n",
        "* `(2, 3)` x `(3,2)` --> `(2,2)` matrix\n",
        "* `(3, 2)` x `(2, 3)` --> `(3,3)` matrix\n",
        "\n",
        "> **Note:** A matrix multiplication like this is also referred to as the [**dot product**](https://www.mathsisfun.com/algebra/vectors-dot-product.html) of two matrices."
      ],
      "metadata": {
        "id": "tx0WhxAKq1iW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "ZjqPpla1MPJA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Element wise multiplication\n",
        "tensor * tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JKCSTsbEq392",
        "outputId": "52642ed1-62a9-42e4-a8be-3e7ad797a088"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([289, 361, 441])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Matrix multiplication --> torch.matmul() or torch.mm() [Alias]\n",
        "torch.matmul(tensor, tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FrCUCBWLq4Az",
        "outputId": "d8f98200-ec80-41dc-a384-157ed2ce06ee"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1091)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The difference between element-wise multiplication and matrix multiplication is the addition of values.\n",
        "\n",
        "For our `tensor` variable with values `[1, 2, 3]`:\n",
        "\n",
        "| Operation | Calculation | Code |\n",
        "| ----- | ----- | ----- |\n",
        "| **Element-wise multiplication** | `[1*1, 2*2, 3*3]` = `[1, 4, 9]` | `tensor * tensor` |\n",
        "| **Matrix multiplication** | `[1*1 + 2*2 + 3*3]` = `[14]` | `tensor.matmul(tensor)` |\n"
      ],
      "metadata": {
        "id": "yIZtBWMeT4pP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "torch.matmul(tensor, tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ofe06Zscq4DU",
        "outputId": "2e9e65db-d9c3-4e04-9b78-66c6f9fe0a13"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 33 µs, sys: 5 µs, total: 38 µs\n",
            "Wall time: 41.7 µs\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1091)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## One of the most common errors in deep learning: shape errors\n",
        "\n",
        "Because much of deep learning is multiplying and performing operations on matrices and matrices have a strict rule about what shapes and sizes can be combined, one of the most common errors you'll run into in deep learning is shape mismatches."
      ],
      "metadata": {
        "id": "L_2xRFaqNNkU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Shapes need to be in the right way\n",
        "tensor_A = torch.tensor([[1, 2],\n",
        "                         [3, 4],\n",
        "                         [5, 6]], dtype=torch.float32)\n",
        "\n",
        "tensor_B = torch.tensor([[7, 10],\n",
        "                         [8, 11],\n",
        "                         [9, 12]], dtype=torch.float32)\n",
        "\n",
        "torch.matmul(tensor_A, tensor_B) # (this will error)"
      ],
      "metadata": {
        "id": "W0b2sH_ot_iT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "72bde06d-41fe-4f64-f1fd-94214590af46"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3539350370.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m                          [9, 12]], dtype=torch.float32)\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_A\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_B\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (this will error)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tensor_A.shape, tensor_B.shape)"
      ],
      "metadata": {
        "id": "qEcwasZ0fYFQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "803603e3-f66a-4b06-e1de-6c6e16b1183c"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 2]) torch.Size([3, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To fix our tensor shape issues, we can manipulate the shape of one of our tensors using a **transpose**\n",
        "\n",
        "A **transpose** switches the axis or dimensions of a given tensor"
      ],
      "metadata": {
        "id": "utv0azPnQCXd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_B, tensor_B.shape"
      ],
      "metadata": {
        "id": "v9xWFf-LuEFo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3c984e6-470b-44e2-e0e5-259a08389e94"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 7., 10.],\n",
              "         [ 8., 11.],\n",
              "         [ 9., 12.]]),\n",
              " torch.Size([3, 2]))"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can perform transposes in PyTorch using either:\n",
        "* `torch.transpose(input, dim0, dim1)` - where `input` is the desired tensor to transpose and `dim0` and `dim1` are the dimensions to be swapped.\n",
        "* `tensor.T` - where `tensor` is the desired tensor to transpose."
      ],
      "metadata": {
        "id": "8gpmf6HiaZB3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_B.T, tensor_B.T.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hu9-dw7SPqMX",
        "outputId": "b724a0cd-32cb-4a43-c460-fa70affeaef5"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 7.,  8.,  9.],\n",
              "         [10., 11., 12.]]),\n",
              " torch.Size([2, 3]))"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The matrix multiplication works when tensor_B is transposed\n",
        "print(f\"Original shapes: tensor_A = {tensor_A.shape}, tensor_B = {tensor_B.shape}\\n\")\n",
        "print(f\"New shapes: tensor_A = {tensor_A.shape} (same as above), tensor_B.T = {tensor_B.T.shape}\\n\")\n",
        "print(f\"Multiplying: {tensor_A.shape} * {tensor_B.T.shape} <- inner dimensions match\\n\")\n",
        "print(\"Output:\\n\")\n",
        "output = torch.matmul(tensor_A, tensor_B.T)\n",
        "print(output)\n",
        "print(f\"\\nOutput shape: {output.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGFh5TlMPqPb",
        "outputId": "b4792a13-65ca-47b0-e4e0-2a3ac39b1f2f"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original shapes: tensor_A = torch.Size([3, 2]), tensor_B = torch.Size([3, 2])\n",
            "\n",
            "New shapes: tensor_A = torch.Size([3, 2]) (same as above), tensor_B.T = torch.Size([2, 3])\n",
            "\n",
            "Multiplying: torch.Size([3, 2]) * torch.Size([2, 3]) <- inner dimensions match\n",
            "\n",
            "Output:\n",
            "\n",
            "tensor([[ 27.,  30.,  33.],\n",
            "        [ 61.,  68.,  75.],\n",
            "        [ 95., 106., 117.]])\n",
            "\n",
            "Output shape: torch.Size([3, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Finding the min, max, mean, sum, etc (tensor aggregation)"
      ],
      "metadata": {
        "id": "Z_1OgGMMVb6p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor\n",
        "x = torch.arange(0, 100, 10)\n",
        "x, x.dtype"
      ],
      "metadata": {
        "id": "knTzXFU-PqST",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "192d9d14-4475-4949-90fc-055208f7f12d"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90]), torch.int64)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the min\n",
        "torch.min(x), x.min()"
      ],
      "metadata": {
        "id": "0R-u74xtPqUU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1860c6e-a965-4941-f701-f4e5d5ac8486"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0), tensor(0))"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the max\n",
        "torch.max(x), x.max()"
      ],
      "metadata": {
        "id": "x8MFbMhpuEJE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7877d6ab-d8e7-4c40-9e34-40bd639e5320"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(90), tensor(90))"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the sum\n",
        "torch.sum(x), x.sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sdDqU4Ck6TpO",
        "outputId": "346f5696-8906-448b-928c-7a62e40cab32"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(450), tensor(450))"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the mean\n",
        "# Note: torch.mean() function requires a tensor of float32 datatype to work\n",
        "torch.mean(x.type(torch.float32)), x.type(torch.float32).mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZzkgx8g6XOh",
        "outputId": "b1579b22-d63e-4c74-bf12-10ec23e06bc8"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(45.), tensor(45.))"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Change tensor datatype\n",
        "\n",
        "a common issue with deep learning operations is having your tensors in different datatypes.\n",
        "\n",
        "If one tensor is in `torch.float64` and another is in `torch.float32`, you might run into some errors.\n",
        "\n",
        "We can change the datatypes of tensors using [`torch.Tensor.type(dtype=None)`](https://pytorch.org/docs/stable/generated/torch.Tensor.type.html) where the `dtype` parameter is the datatype you'd like to use.\n"
      ],
      "metadata": {
        "id": "de40wRPzbgAx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor and check its datatype\n",
        "tensor = torch.arange(10., 100., 10.)\n",
        "tensor.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aCmguByMbMU3",
        "outputId": "1ca90a29-52f7-4f9a-92a8-5998d6b77ef3"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a float16 tensor\n",
        "tensor_float16 = tensor.type(torch.float16)\n",
        "tensor_float16"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhYCAYBPbMYd",
        "outputId": "5674681a-2d04-46a2-d28e-a09c3c06541f"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([10., 20., 30., 40., 50., 60., 70., 80., 90.], dtype=torch.float16)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an int8 tensor\n",
        "tensor_int8 = tensor.type(torch.int8)\n",
        "tensor_int8"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iBd280qrbMbe",
        "outputId": "f57ddfd5-e377-4e03-96dc-fbde1303c0bb"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([10, 20, 30, 40, 50, 60, 70, 80, 90], dtype=torch.int8)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Note:** Different datatypes can be confusing to begin with. But think of it like this, the lower the number (e.g. 32, 16, 8), the less precise a computer stores the value. And with a lower amount of storage, this generally results in faster computation and a smaller overall model. Mobile-based neural networks often operate with 8-bit integers, smaller and faster to run but less accurate than their float32 counterparts."
      ],
      "metadata": {
        "id": "xi8Bcd94b9b5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reshaping, stacking, squeezing and unsqueezing tensors\n",
        "\n",
        "* **Reshaping** - reshapes an input tensor to a defined shape\n",
        "* View - return a view of an input tensor of certain shape but keep the same memory as the original tensor\n",
        "* **Stacking** - combine multiple tensors, on top of each other (vstack) or side by side (hstack)\n",
        "* Squeeze - remove all `1` dimensions from a tensor\n",
        "* Unsqueeze - add a `1` dimension to a target tensor\n",
        "* Permute - return a view of the input with dimensions permuted (swapped) in a certain way"
      ],
      "metadata": {
        "id": "v67JYp5YFhJS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Often times you'll want to *reshape or change the dimensions of your tensors* **without actually changing the values** inside them.\n",
        "\n",
        "To do so, some popular methods are:\n",
        "\n",
        "| Method | One-line description |\n",
        "| ----- | ----- |\n",
        "| [`torch.reshape(input, shape)`](https://pytorch.org/docs/stable/generated/torch.reshape.html#torch.reshape) | Reshapes `input` to `shape` (if compatible), can also use `torch.Tensor.reshape()`. |\n",
        "| [`Tensor.view(shape)`](https://pytorch.org/docs/stable/generated/torch.Tensor.view.html) | Returns a view of the original tensor in a different `shape` but shares the same data as the original tensor. |\n",
        "| [`torch.stack(tensors, dim=0)`](https://pytorch.org/docs/1.9.1/generated/torch.stack.html) | Concatenates a sequence of `tensors` along a new dimension (`dim`), all `tensors` must be same size. |\n",
        "| [`torch.squeeze(input)`](https://pytorch.org/docs/stable/generated/torch.squeeze.html) | Squeezes `input` to remove all the dimenions with value `1`. |\n",
        "| [`torch.unsqueeze(input, dim)`](https://pytorch.org/docs/1.9.1/generated/torch.unsqueeze.html) | Returns `input` with a dimension value of `1` added at `dim`. |\n",
        "| [`torch.permute(input, dims)`](https://pytorch.org/docs/stable/generated/torch.permute.html) | Returns a *view* of the original `input` with its dimensions permuted (rearranged) to `dims`. |\n",
        "\n",
        "Why do any of these?\n",
        "\n",
        "Because deep learning models (neural networks) are all about manipulating tensors in some way. And because of the rules of matrix multiplication, if you've got shape mismatches, you'll run into errors. These methods help you make sure the right elements of your tensors are mixing with the right elements of other tensors.\n"
      ],
      "metadata": {
        "id": "ucFc8rXLcdpz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets create a tensor\n",
        "import torch\n",
        "x = torch.arange(1.0, 10.0)\n",
        "x, x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sCmamjgM6mzM",
        "outputId": "67d1df81-b416-4ca7-9c8c-e258e6dd5662"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.]), torch.Size([9]))"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# input size = 9\n",
        "\n",
        "# Add an extra dimension\n",
        "x_reshaped = x.reshape(9, 1) # 9 x 1 = 9 elements, so re-shaping will work as it matches input size\n",
        "x_reshaped, x_reshaped.shape\n",
        "\n",
        "# reshaped tensor from 1D --> 2D"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ckLPIiYI6nsF",
        "outputId": "b1bdd4b7-7bd6-4465-d2bd-8edbda4df0ba"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[1.],\n",
              "         [2.],\n",
              "         [3.],\n",
              "         [4.],\n",
              "         [5.],\n",
              "         [6.],\n",
              "         [7.],\n",
              "         [8.],\n",
              "         [9.]]),\n",
              " torch.Size([9, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Stack tensors on top of each other\n",
        "\n",
        "x_stacked_vertical = torch.stack([x, x, x, x], dim=0) # vertical stack\n",
        "x_stacked_vertical, x_stacked_vertical.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gy1MgE386nuV",
        "outputId": "b4e3e0b2-d99d-49c3-a75a-0d449a486712"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
              "         [1., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
              "         [1., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
              "         [1., 2., 3., 4., 5., 6., 7., 8., 9.]]),\n",
              " torch.Size([4, 9]))"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_stacked_horizontal = torch.stack([x, x, x, x], dim=1) # horizontal stack\n",
        "x_stacked_horizontal, x_stacked_horizontal.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "reatC3uP6nyG",
        "outputId": "ce5fac49-092b-4421-9069-df7074119c00"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[1., 1., 1., 1.],\n",
              "         [2., 2., 2., 2.],\n",
              "         [3., 3., 3., 3.],\n",
              "         [4., 4., 4., 4.],\n",
              "         [5., 5., 5., 5.],\n",
              "         [6., 6., 6., 6.],\n",
              "         [7., 7., 7., 7.],\n",
              "         [8., 8., 8., 8.],\n",
              "         [9., 9., 9., 9.]]),\n",
              " torch.Size([9, 4]))"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.squeeze() -- removes all single dimensions from a target tensor\n",
        "\n",
        "x_reshaped = x.reshape(1, 9)\n",
        "\n",
        "print(f\"Previous tensor: {x_reshaped}\")\n",
        "print(f\"Previous shape: {x_reshaped.shape}\")\n",
        "\n",
        "# Remove extra dimension from x_reshaped\n",
        "x_squeezed = x_reshaped.squeeze()\n",
        "print(f\"\\nNew tensor: {x_squeezed}\")\n",
        "print(f\"New shape: {x_squeezed.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZlG5oDvM6n8n",
        "outputId": "252064a8-e42a-4803-92cc-e56402e70ca8"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Previous tensor: tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]])\n",
            "Previous shape: torch.Size([1, 9])\n",
            "\n",
            "New tensor: tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.])\n",
            "New shape: torch.Size([9])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## torch.unsqueeze() - Add a single dimension to a target tensor at a specific dim\n",
        "\n",
        "x_unsqueezed = x_squeezed.unsqueeze(dim=0) # vertical addition\n",
        "print(f\"\\nNew tensor: {x_unsqueezed}\")\n",
        "print(f\"New shape: {x_unsqueezed.shape}\")\n",
        "\n",
        "x_unsqueezed2 = x_squeezed.unsqueeze(dim=1) # horizontal dimension\n",
        "print(f\"\\nNew tensor: {x_unsqueezed2}\")\n",
        "print(f\"New shape: {x_unsqueezed2.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Inh13zbUSHDP",
        "outputId": "00aa3749-887f-4c7e-96c1-ed291c4b660c"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "New tensor: tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]])\n",
            "New shape: torch.Size([1, 9])\n",
            "\n",
            "New tensor: tensor([[1.],\n",
            "        [2.],\n",
            "        [3.],\n",
            "        [4.],\n",
            "        [5.],\n",
            "        [6.],\n",
            "        [7.],\n",
            "        [8.],\n",
            "        [9.]])\n",
            "New shape: torch.Size([9, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.permute() - re-arranges the dimensions of a target tensor in a specified order\n",
        "x_original = torch.rand(size=(224, 224, 3)) # [height, width, color_channels]\n",
        "\n",
        "# Permute the original tensor to rearrange the axis (or dim) order\n",
        "x_permuted = x_original.permute(2, 0, 1) # shifts axis 0->1, 1->2, 2->0\n",
        "\n",
        "print(f\"Previous shape: {x_original.shape}\")\n",
        "print(f\"New shape: {x_permuted.shape}\") # [color_channels, height, width]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lD8TKMbhSHGx",
        "outputId": "f3617aa1-0c4d-434d-e726-7dcf539b8c37"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Previous shape: torch.Size([224, 224, 3])\n",
            "New shape: torch.Size([3, 224, 224])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Note**: Because permuting returns a *view* (shares the same data as the original), the values in the permuted tensor will be the same as the original tensor and if you change the values in the view, it will change the values of the original."
      ],
      "metadata": {
        "id": "PvieVrxhgBaH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Indexing (selecting data from tensors)\n",
        "\n",
        "Indexing with Pytorch with similar to indexing with Numpy"
      ],
      "metadata": {
        "id": "k9LeCyNZXkpC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor\n",
        "import torch\n",
        "x = torch.arange(1, 10).reshape(1, 3, 3) # 9 elements -- so 1x3x3 = 9, reshaping will work\n",
        "x, x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0DYXrFrMSHJm",
        "outputId": "c092819d-0506-4927-d6ed-81b2a3e0063c"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[1, 2, 3],\n",
              "          [4, 5, 6],\n",
              "          [7, 8, 9]]]),\n",
              " torch.Size([1, 3, 3]))"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pmgkPNj8Xlu9",
        "outputId": "87121a6d-e268-4bee-ad3b-1f9f7bda6493"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3],\n",
              "        [4, 5, 6],\n",
              "        [7, 8, 9]])"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Indexing values goes outer dimension -> inner dimension (check out the square brackets)."
      ],
      "metadata": {
        "id": "DKZaRpPsiQku"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's index bracket by bracket\n",
        "print(f\"First square bracket:\\n{x[0]}\")\n",
        "print(f\"Second square bracket: {x[0][0]}\")\n",
        "print(f\"Third square bracket: {x[0][0][0]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BIwGDx0eXlzP",
        "outputId": "a0bdb379-c3b0-4f34-ca0e-53836ffb40c4"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First square bracket:\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6],\n",
            "        [7, 8, 9]])\n",
            "Second square bracket: tensor([1, 2, 3])\n",
            "Third square bracket: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# use \":\" to select all of a target dimension\n",
        "\n",
        "# Get all values of 0th and 1st dimension but only index 1 of 2nd dimension\n",
        "x[:, :, 1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_GsyiWenXl3Y",
        "outputId": "3581b16c-a730-4d2a-e9af-3b9277022d49"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2, 5, 8]])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get index 0 of 0th dimension and 1st dimension and all values of 2nd dimension\n",
        "x[0, 0, :]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQkRHacz6oBf",
        "outputId": "82c14c4f-1d6a-48c5-f20c-34b8bbf49170"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PyTorch tensors & NumPy\n",
        "\n",
        "Numpy is a scientific Python numerical computing library, and Pytorch can interact with it\n",
        "\n",
        "* Numpy data to Pytorch tensor --> `torch.from_numpy(ndarray)`\n",
        "* Pytorch tensor to Numpy data --> `tensor.numpy()`"
      ],
      "metadata": {
        "id": "2uKtATn8elSS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Numpy array to tensor\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "array = np.arange(1.0, 8.0)\n",
        "tensor = torch.from_numpy(array)\n",
        "array, tensor\n",
        "\n",
        "# Note:\n",
        "# 1) when converting numpy --> pytorch, pytorch reflects numpy's default datatype of float64 unless specified otherwise\n",
        "# 2) pytorch default datatype is float32"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5qU34GTeaBT",
        "outputId": "c5223cc1-65fd-415d-a155-3d35950ae9b7"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([1., 2., 3., 4., 5., 6., 7.]),\n",
              " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tensor to Numpy array\n",
        "tensor = torch.ones(7)\n",
        "numpy_tensor = tensor.numpy()\n",
        "tensor, numpy_tensor, numpy_tensor.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yjs-f2gzen2d",
        "outputId": "c3dd086c-52c8-4705-9f56-85c01604a616"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1., 1., 1., 1., 1., 1., 1.]),\n",
              " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32),\n",
              " dtype('float32'))"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reproducibility (trying to take the random out of random)\n",
        "\n",
        "For deep learning experiments, to reduce the randomness in neural networks, Pytorch brings the concept of **random seed**"
      ],
      "metadata": {
        "id": "XysS3shjrZig"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Create 2 random tensors\n",
        "random_tensor_A = torch.rand(3, 4)\n",
        "random_tensor_B = torch.rand(3, 4)\n",
        "\n",
        "print(random_tensor_A)\n",
        "print(random_tensor_B)\n",
        "print(random_tensor_A == random_tensor_B)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2AeYdmvXen5a",
        "outputId": "4c9abd3d-04f0-4664-e531-22194bdacd33"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6813, 0.2929, 0.0216, 0.0176],\n",
            "        [0.8069, 0.3560, 0.2092, 0.9883],\n",
            "        [0.9991, 0.8173, 0.1836, 0.5413]])\n",
            "tensor([[0.6350, 0.9935, 0.4471, 0.8088],\n",
            "        [0.2625, 0.2306, 0.1373, 0.8340],\n",
            "        [0.0133, 0.0401, 0.2828, 0.2884]])\n",
            "tensor([[False, False, False, False],\n",
            "        [False, False, False, False],\n",
            "        [False, False, False, False]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[`torch.manual_seed(seed)`](https://pytorch.org/docs/stable/generated/torch.manual_seed.html) comes in, where `seed` is an integer (like `42` but it could be anything) that flavours the randomness."
      ],
      "metadata": {
        "id": "nZd32KbqjUwg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets make random but reproducible tensors\n",
        "\n",
        "# Set the random seed\n",
        "RANDOM_SEED = 42 # flavor of randomness\n",
        "\n",
        "# execute torch.manual_seed() before calling the rand method as it works for only 1 block of code (next block)\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "random_tensor_C = torch.rand(3, 4)\n",
        "\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "random_tensor_D = torch.rand(3, 4)\n",
        "\n",
        "print(random_tensor_C)\n",
        "print(random_tensor_D)\n",
        "print(random_tensor_C == random_tensor_D)\n",
        "\n",
        "# getting same numerical output in both tensors"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W5picLlgen8P",
        "outputId": "a8f42462-f244-4c28-fa64-9ae79f23ec49"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
            "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
            "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
            "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
            "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
            "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
            "tensor([[True, True, True, True],\n",
            "        [True, True, True, True],\n",
            "        [True, True, True, True]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Resource:** For more, on reproducibility in general and random seeds, checkout:\n",
        "> * [The PyTorch reproducibility documentation](https://pytorch.org/docs/stable/notes/randomness.html).\n",
        "> * [The Wikipedia random seed page](https://en.wikipedia.org/wiki/Random_seed) (a good overview of random seeds and pseudorandomness in general)."
      ],
      "metadata": {
        "id": "v-ZcBihhjcjM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Running tensors on GPUs (and making faster computations)\n",
        "\n",
        "GPUs = faster computation on numbers, thanks to CUDA + NVIDIA hardware + PyTorch working behind the scenes"
      ],
      "metadata": {
        "id": "GoGFo2M7stx6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deep learning algorithms require a lot of numerical operations.\n",
        "\n",
        "And by default these operations are often done on a CPU (computer processing unit).\n",
        "\n",
        "However, there's another common piece of hardware called a GPU (graphics processing unit), which is often much faster at performing the specific types of operations neural networks need (matrix multiplications) than CPUs."
      ],
      "metadata": {
        "id": "0j-Lm-1djr2x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the GPU being used, and version\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "WM7ShGRdeaDl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44496ff8-59ed-4e81-fe15-e5e389b78338"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Oct  7 16:50:15 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check for GPU access with Pytorch"
      ],
      "metadata": {
        "id": "zI8lwKWqBnLB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for Gpu access with Pytorch\n",
        "import torch\n",
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "id": "mJNbnjN9sX_x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "148f6ba5-aaf2-437c-ad5f-df46a81f8132"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Device-agnostic code (GPU, CPU)\n",
        "\n",
        "For Pytorch since its capable of running compute on the GPU or CPU, it's best practice to setup device agnostic code\n",
        "\n",
        "i.e.. run on GPU if available, else default to CPU"
      ],
      "metadata": {
        "id": "hOULmVQtHbpJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup device agnostic code - use gpu if available, otherwise cpu\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "id": "n_xZaNMPsYCc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "95bde731-3925-4ec8-e6ff-167905b6db27"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the above output `\"cuda\"` it means we can set all of our PyTorch code to use the available CUDA device (a GPU) and if it output `\"cpu\"`, our PyTorch code will stick with the CPU.\n",
        "\n",
        "> **Note:** In PyTorch, it's best practice to write [**device agnostic code**](https://pytorch.org/docs/master/notes/cuda.html#device-agnostic-code). This means code that'll run on CPU (always available) or GPU (if available).\n"
      ],
      "metadata": {
        "id": "04OSrxyOkXRB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Count number of devices\n",
        "torch.cuda.device_count()"
      ],
      "metadata": {
        "id": "YlRkd3tEsYFY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5ee9859-ea5e-454c-cd02-8fbd84bd506e"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Knowing the number of GPUs PyTorch has access to is helpful incase you wanted to run a specific process on one GPU and another process on another (PyTorch also has features to let you run a process across *all* GPUs)."
      ],
      "metadata": {
        "id": "Y-1EgUhbkgVH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Putting tensors (and models) on GPU\n",
        "\n",
        "The reason we want our tensors/models on the GPU is because using a GPU results in faster computations"
      ],
      "metadata": {
        "id": "2cKEiZ9LLbr6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "GPUs offer far faster numerical computing than CPUs do and if a GPU isn't available, because of our **device agnostic code** (see above), it'll run on the CPU.\n",
        "\n",
        "> **Note:** Putting a tensor on GPU using `to(device)` (e.g. `some_tensor.to(device)`) returns a copy of that tensor, e.g. the same tensor will be on CPU and GPU. To overwrite tensors, reassign them:\n",
        ">\n",
        "> `some_tensor = some_tensor.to(device)`"
      ],
      "metadata": {
        "id": "l-pZRGnDkqBb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor (default on the CPU)\n",
        "tensor = torch.tensor([1, 2, 3])\n",
        "\n",
        "# Tensor not on GPU\n",
        "print(tensor, tensor.device)"
      ],
      "metadata": {
        "id": "Wbk716-leaFx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b233e06-9b03-4a40-e4e4-7c1fbbe1400e"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3]) cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Move tensor to GPU if available\n",
        "tensor_on_gpu = tensor.to(device)\n",
        "tensor_on_gpu"
      ],
      "metadata": {
        "id": "pvewpFm_IuFG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddb5f7f3-e239-44b9-cfbd-475c5aeab438"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you have a GPU available, the above code will output something like:\n",
        "\n",
        "```\n",
        "tensor([1, 2, 3]) cpu\n",
        "tensor([1, 2, 3], device='cuda:0')\n",
        "```\n",
        "\n",
        "Notice the second tensor has `device='cuda:0'`, this means it's stored on the 0th GPU available (GPUs are 0 indexed, if two GPUs were available, they'd be `'cuda:0'` and `'cuda:1'` respectively, up to `'cuda:n'`).\n",
        "\n"
      ],
      "metadata": {
        "id": "iUuDEC81k7KN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Moving tensors back to the CPU"
      ],
      "metadata": {
        "id": "ML58ZJtaL9_S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# If tensor is on GPU, can't transform it to Numpy (numpy only on CPU)\n",
        "\n",
        "# To fix the GPU tensor with Numpy issue, first set it to CPU\n",
        "tensor_back_on_cpu = tensor_on_gpu.cpu().numpy()\n",
        "tensor_back_on_cpu"
      ],
      "metadata": {
        "id": "pQ3zcVxDIuHw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e42d594e-e93b-4599-d6ba-4d4e9252aecd"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    }
  ]
}