{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53d240da",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73220ad8",
   "metadata": {},
   "source": [
    "# 5. IMPROVING a Model (Hyperparameter Tuning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6caa87",
   "metadata": {},
   "source": [
    "The **first predictions** you make with a model are generally referred to as **baseline predictions**. The same goes with the first evaluation metrics you get. These are generally referred to as baseline metrics.\n",
    "so ,**first model = baseline model**\n",
    "\n",
    "Your next goal is to improve upon these baseline metrics.\n",
    "\n",
    "Two of the main methods to improve baseline metrics are from a data perspective and a model perspective."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115b9e02",
   "metadata": {},
   "source": [
    "From a data perspective asks:\n",
    "\n",
    "* Could we collect more data? In machine learning, more data is generally better, as it gives a model more opportunities to learn patterns.\n",
    "* Could we improve our data? This could mean filling in missing values or finding a better encoding (turning things into numbers) strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed5609e",
   "metadata": {},
   "source": [
    "From a model perspective asks:\n",
    "\n",
    "* Is there a better model we could use? If you've started out with a simple model, could you use a more complex one? (we saw an example of this when looking at the [Scikit-Learn machine learning map](https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html), ensemble methods are generally considered more complex models)\n",
    "* Could we improve the current model? If the model you're using performs well straight out of the box, can the hyperparameters be tuned to make it even better?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a92789a",
   "metadata": {},
   "source": [
    "**Note**: Patterns in data are also often referred to as data parameters. The difference between parameters and hyperparameters is a machine learning model seeks to find parameters in data on its own, where as, hyperparameters are settings on a model which a user (you) can adjust.\n",
    "\n",
    "Hyperparameters vs Parameters\n",
    "\n",
    "* Parameters = model find these patterns in data\n",
    "* Hyperparameters = settings on a model you can adjust to (potentially) improve its ability to find patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "655176ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b5dedef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.get_params() # get the parameters of a model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e8e827",
   "metadata": {},
   "source": [
    "The default hyperparameters on a machine learning model may find patterns in data well. But there's a chance a adjusting the hyperparameters may improve a models performance.\n",
    "\n",
    "Every machine learning model will have different hyperparameters you can tune. You might be thinking, \"how the hell do I remember all of these?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ecaa615",
   "metadata": {},
   "source": [
    "Sklearn Machine learning map --> sklearn doc --> model --> parameters (Hyper Parameters)\n",
    "\n",
    "Adjusting hyperparameters is usually an experimental process to figure out which are best. As there's no real way of knowing which hyperparameters will be best when starting out."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98d9bd1",
   "metadata": {},
   "source": [
    "The good news is, the process we're taking with the [Random Forest](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) and tuning its hyperparameters, can be used for other machine learning models in Scikit-Learn. The only difference is, with a different model, the hyperparameters you tune will be different.\n",
    "\n",
    "So for Random Forest:\n",
    "\n",
    "1. By hand \n",
    "2. Randomly with [RandomSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html)\n",
    "3. Exhaustively with [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
