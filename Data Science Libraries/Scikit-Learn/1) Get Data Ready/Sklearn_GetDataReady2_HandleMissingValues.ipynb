{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "third-founder",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cultural-facility",
   "metadata": {},
   "source": [
    "## 1.2) Dealing with missing values in data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trained-blame",
   "metadata": {},
   "source": [
    "1) Fill them with some value (also known as imputation)\n",
    "\n",
    "2) Remove the samples with missing data altogether\n",
    "\n",
    "Two methods --> both are okay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "super-kidney",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Make</th>\n",
       "      <th>Colour</th>\n",
       "      <th>Odometer (KM)</th>\n",
       "      <th>Doors</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>35431.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15323.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BMW</td>\n",
       "      <td>Blue</td>\n",
       "      <td>192714.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>19943.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>84714.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>28343.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>White</td>\n",
       "      <td>154365.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13434.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>Blue</td>\n",
       "      <td>181577.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14043.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Make Colour  Odometer (KM)  Doors    Price\n",
       "0   Honda  White        35431.0    4.0  15323.0\n",
       "1     BMW   Blue       192714.0    5.0  19943.0\n",
       "2   Honda  White        84714.0    4.0  28343.0\n",
       "3  Toyota  White       154365.0    4.0  13434.0\n",
       "4  Nissan   Blue       181577.0    3.0  14043.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_df = pd.read_csv(\"data/car-sales-extended-missing-data.csv\")\n",
    "car_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "qualified-comparative",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Make             49\n",
       "Colour           50\n",
       "Odometer (KM)    50\n",
       "Doors            50\n",
       "Price            50\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many missing values are there in each column\n",
    "car_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cooperative-queens",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split into X & y and train/test set\n",
    "X = car_df.drop(\"Price\", axis=1)\n",
    "y = car_df[\"Price\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "demonstrated-thing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((800, 4), (200, 4), (800,), (200,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "entitled-pressing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can't turn the categories into numericals because of the presense of missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imperial-subscriber",
   "metadata": {},
   "source": [
    "### Option 1: - Filling missing data with Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "herbal-parliament",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Follow order of column\n",
    "\n",
    "# String columns must be filled with strings\n",
    "# Numerical columns can be filled with mean,median,mode or other numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "lonely-reset",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0    811\n",
       "5.0     75\n",
       "3.0     64\n",
       "Name: Doors, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find out how many doors are there of each number\n",
    "car_df[\"Doors\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "durable-limit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling the missing values (cells)\n",
    "\n",
    "# Fill the \"Make\" column\n",
    "car_df[\"Make\"].fillna(\"missing\",inplace=True) # change dataframe immediately\n",
    "\n",
    "# Fill the \"Colour\" column\n",
    "car_df[\"Colour\"].fillna(\"missing\",inplace=True)\n",
    "\n",
    "# Fill the \"Odometer (KM)\" column\n",
    "car_df[\"Odometer (KM)\"].fillna(car_df[\"Odometer (KM)\"].mean(), inplace=True)\n",
    "\n",
    "# Fill the \"Doors\" column\n",
    "car_df[\"Doors\"].fillna(4,inplace=True) # 4 is max number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "urban-small",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Make              0\n",
       "Colour            0\n",
       "Odometer (KM)     0\n",
       "Doors             0\n",
       "Price            50\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check our dataframe again for missing values again \n",
    "car_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "congressional-sequence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with missing data\n",
    "# missing price values in this case\n",
    "car_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "expensive-campbell",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Make             0\n",
       "Colour           0\n",
       "Odometer (KM)    0\n",
       "Doors            0\n",
       "Price            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_df.isna().sum() # Perfect - no missing values in dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "mineral-testing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "950"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many data remaining\n",
    "len(car_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "matched-paragraph",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into X & y and train/test set\n",
    "X = car_df.drop(\"Price\", axis=1)\n",
    "y = car_df[\"Price\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ecological-connectivity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((760, 4), (190, 4), (760,), (190,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "stopped-worry",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000e+00, 1.00000e+00, 0.00000e+00, ..., 0.00000e+00,\n",
       "        3.54310e+04, 1.53230e+04],\n",
       "       [1.00000e+00, 0.00000e+00, 0.00000e+00, ..., 1.00000e+00,\n",
       "        1.92714e+05, 1.99430e+04],\n",
       "       [0.00000e+00, 1.00000e+00, 0.00000e+00, ..., 0.00000e+00,\n",
       "        8.47140e+04, 2.83430e+04],\n",
       "       ...,\n",
       "       [0.00000e+00, 0.00000e+00, 1.00000e+00, ..., 0.00000e+00,\n",
       "        6.66040e+04, 3.15700e+04],\n",
       "       [0.00000e+00, 1.00000e+00, 0.00000e+00, ..., 0.00000e+00,\n",
       "        2.15883e+05, 4.00100e+03],\n",
       "       [0.00000e+00, 0.00000e+00, 0.00000e+00, ..., 0.00000e+00,\n",
       "        2.48360e+05, 1.27320e+04]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer \n",
    "\n",
    "categorical_features = [\"Make\",\"Colour\",\"Doors\"]\n",
    "one_hot = OneHotEncoder()\n",
    "transformer = ColumnTransformer([\n",
    "    (\"one_hot\",one_hot,categorical_features)],\n",
    "    remainder=\"passthrough\")\n",
    "\n",
    "transformed_X = transformer.fit_transform(car_df)\n",
    "transformed_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "varying-region",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "level-briefs",
   "metadata": {},
   "source": [
    "### Option 2: - Filling missing data with Scikit-Learn and transforming categorical data with Scikit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "genuine-tucson",
   "metadata": {},
   "source": [
    "SimpleImputer() transforms data by filling missing values with a given strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thrown-order",
   "metadata": {},
   "source": [
    "The main takeaways:\n",
    "\n",
    "* Split your data first (into train/test), always keep your training & test data separate\n",
    "\n",
    "* Fill/transform the training set and test sets separately (this goes for filling data with pandas as well)\n",
    "\n",
    "* Don't use data from the future (test set) to fill data from the past (training set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cooked-satin",
   "metadata": {},
   "source": [
    "The video shows filling and transforming the entire dataset (X) and although the techniques are correct, it's best to fill and transform training and test sets separately\n",
    "\n",
    "Hence, the code below was corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "planned-private",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Make</th>\n",
       "      <th>Colour</th>\n",
       "      <th>Odometer (KM)</th>\n",
       "      <th>Doors</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>35431.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15323.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BMW</td>\n",
       "      <td>Blue</td>\n",
       "      <td>192714.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>19943.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>84714.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>28343.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>White</td>\n",
       "      <td>154365.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13434.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>Blue</td>\n",
       "      <td>181577.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14043.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Make Colour  Odometer (KM)  Doors    Price\n",
       "0   Honda  White        35431.0    4.0  15323.0\n",
       "1     BMW   Blue       192714.0    5.0  19943.0\n",
       "2   Honda  White        84714.0    4.0  28343.0\n",
       "3  Toyota  White       154365.0    4.0  13434.0\n",
       "4  Nissan   Blue       181577.0    3.0  14043.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_df2 = pd.read_csv(\"data/car-sales-extended-missing-data.csv\")\n",
    "car_df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "alpine-nebraska",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Make             49\n",
       "Colour           50\n",
       "Odometer (KM)    50\n",
       "Doors            50\n",
       "Price            50\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_df2.isna().sum() # See the number of missing values in each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "future-wright",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Make             47\n",
       "Colour           46\n",
       "Odometer (KM)    48\n",
       "Doors            47\n",
       "Price             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the rows with no labels\n",
    "\n",
    "# Drop the rows that have no price values\n",
    "car_df2.dropna(subset=[\"Price\"],inplace=True)\n",
    "car_df2.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brave-debate",
   "metadata": {},
   "source": [
    "the data is split into train and test before any filling missing values or transformations take place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "filled-venice",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split into X & y\n",
    "X = car_df2.drop(\"Price\", axis=1)\n",
    "y = car_df2[\"Price\"]\n",
    "\n",
    "# Split data into train and test\n",
    "np.random.seed(42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "recorded-johnston",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((760, 4), (190, 4), (760,), (190,))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "printable-context",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Make             47\n",
       "Colour           46\n",
       "Odometer (KM)    48\n",
       "Doors            47\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check missing values in X (both train and test dataset)\n",
    "X.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suburban-balance",
   "metadata": {},
   "source": [
    "Let's fill the missing values. \n",
    "We'll fill the training and test values separately to ensure training data stays with the training data and test data stays with the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hourly-ensemble",
   "metadata": {},
   "source": [
    "Note: We use fit_transform() on the training data and transform() on the testing data. In essence, we learn the patterns in the training set and transform it via imputation (fit, then transform). Then we take those same patterns and fill the test set (transform only)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "billion-missile",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Honda', 'White', 4.0, 71934.0],\n",
       "       ['Toyota', 'Red', 4.0, 162665.0],\n",
       "       ['Honda', 'White', 4.0, 42844.0],\n",
       "       ...,\n",
       "       ['Toyota', 'White', 4.0, 196225.0],\n",
       "       ['Honda', 'Blue', 4.0, 133117.0],\n",
       "       ['Honda', 'missing', 4.0, 150582.0]], dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fill missing values with Scikit-Learn\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Fill categorical values with \"missing\" and numerical values with mean\n",
    "# Imputation --> Find the missing values and fill them\n",
    "# Define some imputers\n",
    "\n",
    "# strategy=\"constant\" = go to the categorical columns, if u find a missing value, \n",
    "# constantly fill them with the string missing, or mean or a default value\n",
    "\n",
    "cat_imputer = SimpleImputer(strategy=\"constant\",fill_value=\"missing\")\n",
    "door_imputer = SimpleImputer(strategy=\"constant\",fill_value=4)\n",
    "num_imputer = SimpleImputer(strategy=\"mean\")\n",
    "\n",
    "# Define columns\n",
    "cat_features = [\"Make\",\"Colour\"] # category column\n",
    "door_features = [\"Doors\"] # a category column\n",
    "num_features = [\"Odometer (KM)\"] # numerical column\n",
    "\n",
    "# Create an imputer (something that fills missing data)\n",
    "# pass in the imputations (all the different transformations to do)\n",
    "\n",
    "# Takes a list and tuples within exists multiple different transformers\n",
    "imputer = ColumnTransformer([\n",
    "    # name, imputer to use, features on which to use the imputer\n",
    "    (\"cat_imputer\",cat_imputer,cat_features),\n",
    "    (\"door_imputer\",door_imputer,door_features),\n",
    "    (\"num_imputer\",num_imputer,num_features)\n",
    "])\n",
    "\n",
    "# Transform data\n",
    "# Fill train and test values separately\n",
    "filled_X_train = imputer.fit_transform(X_train) # fit_transform imputes the missing values from the training set and fills them simultaneously\n",
    "filled_X_test = imputer.transform(X_test) # tranform takes the imputing missing values from the training set and fills the test set with them\n",
    "\n",
    "# Check filled X_train\n",
    "filled_X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "systematic-schema",
   "metadata": {},
   "source": [
    "Now we've filled our missing values, let's check how many are missing from each set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "grateful-thriller",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get our transformed data array's back into DataFrame's\n",
    "car_sales_filled_train = pd.DataFrame(filled_X_train, \n",
    "                                      columns=[\"Make\", \"Colour\", \"Doors\", \"Odometer (KM)\"])\n",
    "\n",
    "car_sales_filled_test = pd.DataFrame(filled_X_test, \n",
    "                                     columns=[\"Make\", \"Colour\", \"Doors\", \"Odometer (KM)\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "recognized-warrior",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Make             0\n",
       "Colour           0\n",
       "Doors            0\n",
       "Odometer (KM)    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check missing data in training set\n",
    "car_sales_filled_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "impaired-consent",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Make             0\n",
       "Colour           0\n",
       "Doors            0\n",
       "Odometer (KM)    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check missing data in test set\n",
    "car_sales_filled_test.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assisted-yeast",
   "metadata": {},
   "source": [
    "### Now that there are no missing values\n",
    "\n",
    "### Convert the data into numbers (numerical data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "silver-country",
   "metadata": {},
   "source": [
    "using one hot encoding.\n",
    "\n",
    "Again, keeping our training and test data separate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "hollow-pressure",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import OneHotEncoder class from sklearn\n",
    "\n",
    "# Turn the categories (Make and Colour) into numbers, as well as Door\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer \n",
    "\n",
    "# Now let's one hot encode the features\n",
    "\n",
    "categorical_features = [\"Make\",\"Colour\",\"Doors\"]\n",
    "one_hot = OneHotEncoder()\n",
    "transformer = ColumnTransformer([\n",
    "    (\"one_hot\",one_hot,categorical_features)],\n",
    "    remainder=\"passthrough\")\n",
    "\n",
    "# Fill train and test values separately\n",
    "transformed_X_train = transformer.fit_transform(car_sales_filled_train) # fit and transform the training data\n",
    "transformed_X_test = transformer.transform(car_sales_filled_test) # transform the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "therapeutic-watershed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000e+00, 1.00000e+00, 0.00000e+00, ..., 1.00000e+00,\n",
       "        0.00000e+00, 7.19340e+04],\n",
       "       [0.00000e+00, 0.00000e+00, 0.00000e+00, ..., 1.00000e+00,\n",
       "        0.00000e+00, 1.62665e+05],\n",
       "       [0.00000e+00, 1.00000e+00, 0.00000e+00, ..., 1.00000e+00,\n",
       "        0.00000e+00, 4.28440e+04],\n",
       "       ...,\n",
       "       [0.00000e+00, 0.00000e+00, 0.00000e+00, ..., 1.00000e+00,\n",
       "        0.00000e+00, 1.96225e+05],\n",
       "       [0.00000e+00, 1.00000e+00, 0.00000e+00, ..., 1.00000e+00,\n",
       "        0.00000e+00, 1.33117e+05],\n",
       "       [0.00000e+00, 1.00000e+00, 0.00000e+00, ..., 1.00000e+00,\n",
       "        0.00000e+00, 1.50582e+05]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check transformed and filled X_train\n",
    "transformed_X_train.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "wired-claim",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ordered-insider",
   "metadata": {},
   "source": [
    "### Fit a model\n",
    "\n",
    "Now we've filled and transformed our data, ensuring the training and test sets have been kept separate. Let's fit a model to the training set and evaluate it on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cooperative-syndicate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we've got our data as numbers and filled (no missing values)\n",
    "# The process of filling missing values --> imputation\n",
    "# The process of converting non-numerical values to numerical --> feature engineering or feature encoding\n",
    "\n",
    "# Lets fit a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "little-certification",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21229043336119102"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we've transformed X, let's see if we can fit a model\n",
    "np.random.seed(42)\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Setup model\n",
    "model = RandomForestRegressor()\n",
    "\n",
    "# Make sure to use transformed (filled and one-hot encoded X data)\n",
    "model.fit(transformed_X_train, y_train)\n",
    "model.score(transformed_X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sufficient-uzbekistan",
   "metadata": {},
   "source": [
    "Fitting the model on the data involves passing it the data and asking it to figure out the patterns.\n",
    "\n",
    "If there are labels (supervised learning), the model tries to work out the relationship between the data and the labels.\n",
    "\n",
    "If there are no labels (unsupervised learning), the model tries to find patterns and group similar samples together."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equipped-hunter",
   "metadata": {},
   "source": [
    "Use the model to make a prediction\n",
    "The whole point of training a machine learning model is to use it to make some kind of prediction in the future.\n",
    "\n",
    "Once our model instance is trained, you can use the predict() method to predict a target value given a set of features. In other words, use the model, along with some unlabelled data to predict the label.\n",
    "\n",
    "Note, data you predict on has to be in the same shape as data you trained on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assured-vacuum",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
